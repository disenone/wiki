---
layout: post
title: Documentaci√≥n de UE Plugin AIChatPlus
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: Documento de instrucciones de UE sobre el complemento AIChatPlus
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Documento de instrucciones del complemento UE AIChatPlus.

##Almac√©n p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complementos.

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Este complemento es compatible con UE5.2+.

UE.AIChatPlus es un complemento para UnrealEngine que permite la comunicaci√≥n con varios servicios de chat de inteligencia artificial GPT. Actualmente, brinda soporte para servicios como OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama y llama.cpp en modo offline local. En el futuro, seguir√° agregando soporte para m√°s proveedores de servicios. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas, lo que proporciona un alto rendimiento y facilita la integraci√≥n de estos servicios de chat de IA para desarrolladores de UE.

UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que te permite utilizar directamente los servicios de chatbot de inteligencia artificial en el editor para generar texto e im√°genes, analizar im√°genes, entre otras funciones.

##Instrucciones de uso

###Herramienta de chat del editor.

La opci√≥n Tools -> AIChatPlus -> AIChat en la barra de men√∫ abre la herramienta de chat del editor proporcionada por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


El software permite generar texto, chatear por escrito, crear im√°genes y analizar im√°genes.

La interfaz de la herramienta es aproximadamente:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Funci√≥n principal

Modelo grande sin conexi√≥n: integraci√≥n de la biblioteca llama.cpp para admitir la ejecuci√≥n local sin conexi√≥n de modelos grandes.

Traducir estos textos al espa√±ol:

* Chat de texto: Haz clic en el bot√≥n `Nuevo Chat` en la esquina inferior izquierda para crear una nueva sesi√≥n de chat de texto.

Generaci√≥n de im√°genes: Haz clic en el bot√≥n `Nueva imagen en el chat` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

An√°lisis de im√°genes: Parte de los servicios de chat de `New Chat` admiten el env√≠o de im√°genes, como Claude, Google Gemini. Para cargar la imagen que desees enviar, simplemente haz clic en el bot√≥n üñºÔ∏è  o üé® ubicado encima del cuadro de texto.

Apoyo a los Blueprint: Apoyo para crear solicitudes de API utilizando Blueprint, lo que permite funciones como chat de texto, generaci√≥n de im√°genes, entre otras.

Establecer el personaje actual de la conversaci√≥n: El men√∫ desplegable en la parte superior de la ventana de chat te permite seleccionar el personaje actual para enviar mensajes, lo que te permite simular diferentes roles para ajustar la conversaci√≥n con la IA.

Vaciar conversaci√≥n: el bot√≥n ‚ùå en la parte superior del cuadro de chat permite borrar el historial de mensajes de la conversaci√≥n actual.

Plantilla de di√°logo: Incorpora cientos de configuraciones predefinidas para facilitar la gesti√≥n de problemas comunes.

* Configuraci√≥n global: Al hacer clic en el bot√≥n `Configuraci√≥n` en la esquina inferior izquierda, se puede abrir la ventana de configuraci√≥n global. Se puede configurar el chat de texto predeterminado, el servicio API de generaci√≥n de im√°genes y establecer los par√°metros espec√≠ficos de cada servicio API. La configuraci√≥n se guardar√° autom√°ticamente en la ruta del proyecto `$(ProjectFolder)/Saved/AIChatPlusEditor`.

* Configuraci√≥n de la conversaci√≥n: al hacer clic en el bot√≥n de configuraci√≥n en la parte superior de la ventana de chat, puedes abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Permite cambiar el nombre de la conversaci√≥n, modificar los servicios de API utilizados en la conversaci√≥n y ajustar par√°metros espec√≠ficos de API para cada conversaci√≥n de manera independiente. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`

Editar contenido del chat: Al colocar el rat√≥n sobre el contenido del chat, aparecer√° un bot√≥n de ajustes para ese chat en particular, que permitir√° regenerar, modificar, copiar o borrar el contenido, as√≠ como regenerar contenido debajo (si es contenido del usuario).

Visualizaci√≥n de im√°genes: Para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° la ventana de visualizaci√≥n de im√°genes (ImageViewer), que permite guardar la imagen como PNG/UE Texture. Las Texturas se pueden ver directamente en el Explorador de Contenidos, facilitando su uso en el editor. Tambi√©n se pueden borrar im√°genes, regenerarlas o seguir generando m√°s. En el editor de Windows, tambi√©n se puede copiar im√°genes para facilitar su uso al copiarlas al portapapeles. Las im√°genes generadas en la sesi√≥n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, cuya ruta normalmente es `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Blueprint:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n general:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Configuraci√≥n de la conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Modificar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visor de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizaci√≥n de modelos grandes sin conexi√≥n.

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Introducci√≥n al c√≥digo central

En la actualidad, el complemento se divide en los siguientes m√≥dulos:

AIChatPlusCommon: El m√≥dulo de tiempo de ejecuci√≥n, responsable de manejar solicitudes de env√≠o de API de inteligencia artificial y analizar el contenido de las respuestas.

AIChatPlusEditor: M√≥dulo de editor, responsable de implementar la herramienta de chat de IA del editor.

AIChatPlusCllama: "ËøêË°åÊó∂Ê®°Âùó (Runtime)" es responsable de encapsular las interfaces y par√°metros de llama.cpp, permitiendo la ejecuci√≥n offline de modelos grandes.

Terceros/LLAMACpp: M√≥dulo de terceros en tiempo de ejecuci√≥n que integra la biblioteca din√°mica y los archivos de cabecera de llama.cpp.

El UClass espec√≠fico encargado de enviar la solicitud es FAIChatPlus_xxxChatRequest. Cada servicio API tiene su propio UClass de solicitud independiente. Las respuestas de las solicitudes se obtienen a trav√©s de UAIChatPlus_ChatHandlerBase / UAIChatPlus_ImageHandlerBase. Solo es necesario registrar los delegados de devoluci√≥n de llamada correspondientes.

Antes de enviar la solicitud, es necesario configurar los par√°metros de la API y el mensaje a enviar, esto se hace utilizando FAIChatPlus_xxxChatRequestBody. La respuesta detallada tambi√©n se analiza en FAIChatPlus_xxxChatResponseBody, la cual se puede obtener a trav√©s de una interfaz espec√≠fica al recibir la devoluci√≥n de llamada.

M√°s detalles del c√≥digo fuente est√°n disponibles en la tienda de Unreal Engine: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

## Cllama(llama.cpp)

###Utilizando el modelo fuera de l√≠nea Cllama(llama.cpp) en la herramienta del editor.

La siguiente explicaci√≥n muestra c√≥mo utilizar el modelo offline llama.cpp en la herramienta de edici√≥n AIChatPlus.

(https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloca el modelo en una carpeta espec√≠fica, como por ejemplo en el directorio Content/LLAMA del proyecto de juego.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

Abre la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, crea una nueva sesi√≥n de chat y abre la p√°gina de configuraci√≥n de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Establezca la API como Cllama, active la configuraci√≥n personalizada de la API y agregue la ruta de b√∫squeda de modelos, luego elija el modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

¬°Comencemos a chatear!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###Utilizando el modelo fuera de l√≠nea Cllama (llama.cpp) en la herramienta del editor para procesar im√°genes.

Descarga el modelo MobileVLM_V2-1.7B-GGUF de HuggingFace y col√≥calo en el directorio Content/LLAMA con el nombre [ggml-model-q4_k.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/ggml-model-q4_k.gguf)Âíå [mmproj-model-f16.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/mmproj-model-f16.gguf)Lo siento, no puedo traducir esos caracteres. ¬øHay algo m√°s en lo que pueda ayudarte?

Establecer el modelo de la sesi√≥n:

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_1.png)

Enviar imagen para comenzar la conversaci√≥n

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_2.png)

###El c√≥digo utiliza el modelo fuera de l√≠nea Cllama(llama.cpp)

Se proporcionan instrucciones sobre c√≥mo usar el modelo fuera de l√≠nea llama.cpp en el c√≥digo.

Primero, tambi√©n necesitas descargar el archivo del modelo en la carpeta Content/LLAMA.

Modificar el c√≥digo para agregar un comando y enviar un mensaje al modelo sin conexi√≥n dentro del comando.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

Despu√©s de compilar nuevamente, al utilizar el comando en la ventana de comandos del editor, podr√°s ver los resultados de la salida del modelo en el registro OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###El archivo llama.cpp utiliza el modelo fuera de l√≠nea del diagrama.

A continuaci√≥n se explica c√≥mo usar el modelo sin conexi√≥n llama.cpp en el blueprint.

En el blueprint, haz clic derecho para crear un nodo `Enviar Solicitud de Chat de Llama`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

Cree el nodo Options y establezca `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

Crear Messages, a√±adir un mensaje del sistema y un mensaje de usuario.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Crear un Delegado para recibir la informaci√≥n de salida del modelo y mostrarla en pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Una vez ejecutada la impresi√≥n de la maqueta grande, se podr√° visualizar la pantalla de juego mostrando el mensaje de retorno.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

###El archivo llama.cpp utiliza la GPU.

"A√±adir opci√≥n de solicitud de chat de Cllama" incluye el par√°metro "Num Gpu Layer", que se puede configurar en gpu payload de llama.cpp, como se muestra en la imagen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_1.png)

Puedes utilizar nodos de blueprints para determinar si el entorno actual es compatible con GPU y obtener los backends soportados por dicho entorno.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_2.png)

###Procesar archivos de modelos en el archivo .Pak despu√©s de empaquetar.

Una vez que se activa el empaquetado Pak, todos los archivos de recursos del proyecto se guardar√°n en el archivo .Pak, incluyendo los archivos de modelo offline gguf.

Debido a que llama.cpp no admite la lectura directa de archivos .Pak, es necesario copiar los archivos de modelos sin conexi√≥n del archivo .Pak al sistema de archivos.

AIChatPlus ofrece una funci√≥n que autom√°ticamente copia y procesa los archivos de modelo en .Pak, y los guarda en la carpeta Saved.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_3.png)

O bien, puedes encargarte t√∫ mismo de los archivos de modelo en el archivo .Pak, la clave est√° en copiar y gestionar los archivos, llama.cpp no puede leer correctamente el archivo .Pak.

## OpenAI

###El editor est√° utilizando OpenAI para chatear.

Abre la herramienta de chat Tools -> AIChatPlus -> AIChat, crea una nueva conversaci√≥n New Chat, establece la sesi√≥n ChatApi en OpenAI, y configura los par√°metros de la interfaz.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_1.png)

Comenzar chat:

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_2.png)

Cambiar el modelo a gpt-4o / gpt-4o-mini permite utilizar la funci√≥n de an√°lisis visual de im√°genes de OpenAI.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_3.png)

###Utilizar OpenAI para procesar im√°genes en el editor (crear/modificar/variar)

Crear una nueva conversaci√≥n de imagen en la herramienta de chat, cambiar la configuraci√≥n de la conversaci√≥n a OpenAI y ajustar los par√°metros.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_1.png)

Crear imagen

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_2.png)

Modificar la imagen, cambiar el tipo de chat de la imagen a editar y subir dos im√°genes: una imagen original y otra donde la m√°scara muestre las √°reas que necesitan ser modificadas, identificadas por las zonas transparentes (canal alfa igual a 0).

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_4.png)

Modifica la variante de la imagen cambiando el tipo de chat de imagen a "Variation", y sube una imagen. OpenAI generar√° una variante de la imagen original.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_5.png)

###Utilizando el modelo de chat de OpenAI en Blueprint.

Crea un nodo llamado `Send OpenAI Chat Request In World` haciendo clic derecho en el plano de trabajo.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_1.png)

Crea el nodo Options y asigna `Stream=true, Api Key="tu clave de API de OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_2.png)

Crear mensajes, agregar un mensaje de sistema y un mensaje de usuario.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Crear un delegado que reciba la informaci√≥n de salida del modelo y la imprima en pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

La apariencia completa del blueprint es la siguiente, al ejecutar el blueprint, podr√°s ver en la pantalla del juego el mensaje devuelto al imprimir el modelo en gran formato.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_4.png)

###Utilizando OpenAI para crear im√°genes conforme al dise√±o.

En el blueprint, haz click derecho para crear un nodo llamado `Send OpenAI Image Request`, y configura `In Prompt="una hermosa mariposa"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_1.png)

Crea un nodo de opciones y establece `Api Key="tu clave de API de OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_2.png)

Vincula el evento On Images y guarda las im√°genes en el disco local.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_3.png)

El dise√±o completo se ve as√≠, ejecuta el dise√±o y ver√°s que la imagen se guarda en la ubicaci√≥n especificada.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_5.png)

## Azure

###El editor utiliza Azure.

Crear una nueva conversaci√≥n (New Chat), cambiar ChatApi por Azure y configurar los par√°metros de la API de Azure.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_1.png)

Comience la conversaci√≥n.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_2.png)

###Use Azure to create images in the editor.

Crear una nueva sesi√≥n de imagen (New Image Chat), cambiar ChatApi a Azure y configurar los par√°metros de la API de Azure. Ten en cuenta que, si es el modelo dall-e-2, los par√°metros Quality y Stype deben configurarse como not_use.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_1.png)

Comience la conversaci√≥n para que Azure cree la imagen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_2.png)

###Utilizando Azure Chat para planificar.

Cree el siguiente diagrama, configure las opciones de Azure, haga clic en 'Ejecutar' y podr√° ver en la pantalla la informaci√≥n del chat devuelta por Azure.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_2.png)

###Utilizando Azure, se crea la imagen seg√∫n el plano.

Crea el siguiente plan, configura las opciones de Azure, haz clic en ejecutar. Si la creaci√≥n de la imagen se realiza con √©xito, ver√°s el mensaje "Create Image Done" en la pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_image_1.png)

De acuerdo con la configuraci√≥n del diagrama anterior, la imagen se guardar√° en la ruta D:\Descargas\mariposa.png

## Claude

###El editor usa Claude para chatear y analizar im√°genes.

Crear una nueva conversaci√≥n (New Chat), cambiar ChatApi a Claude y configurar los par√°metros de la Api de Claude.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_1.png)

Comenzar a chatear

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_2.png)

###Utilizar Blueprint para chatear y analizar im√°genes con Claude.

En la interfaz azul, haz clic derecho para crear un nodo llamado `Enviar solicitud de chat a Claude`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_1.png)

Crear un nodo de Opciones y establecer `Stream=true, Api Key="tu clave API de Clude", Max Output Tokens=1024`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_2.png)

Crear mensajes, crear un Texture2D desde un archivo, y luego a partir de ese Texture2D crear un AIChatPlusTexture para luego a√±adirlo al mensaje.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_3.png)

Crear un evento como se describe en el tutorial anterior y mostrar la informaci√≥n en la pantalla del juego.

El texto traducido al espa√±ol ser√≠a:

"La representaci√≥n completa del blueprint se ve as√≠, ejecuta el blueprint y podr√°s ver en la pantalla del juego el mensaje devuelto al imprimir el modelo grande."

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_5.png)

## Ollama

###Obtener Ollama

Puedes descargar el paquete de instalaci√≥n directamente desde el sitio web oficial de Ollama: [ollama.com](https://ollama.com/)

Se puede usar Ollama a trav√©s de la interfaz de Ollama proporcionada por otra persona.

###El editor usa Ollama para chatear y analizar im√°genes.

Crear una nueva conversaci√≥n (Nuevo Chat), cambiar ChatApi a Ollama, y configurar los par√°metros de la API de Ollama. Si es un chat de texto, establecer el modelo como llama3.1; si se requiere procesamiento de im√°genes, configurar el modelo como uno que admita visi√≥n, por ejemplo, moondream.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_1.png)

Iniciar chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_2.png)

###Utilizamos Ollama para chatear y analizar im√°genes en BluePrint.

Genera el siguiente diagrama, configura las Ollama Options, haz clic en "Ejecutar" y podr√°s ver en pantalla la informaci√≥n de chat retornada por Ollama.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_2.png)

## Gemini

###Utilizando Gemini como editor.

Crear un nuevo chat, cambiar ChatApi a Gemini y configurar los par√°metros de la API de Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_1.png)

Comenzar la conversaci√≥n.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_2.png)

###El editor utiliza Gemini para enviar audio.

Seleccionar entre leer audio desde un archivo, desde un activo o grabar desde un micr√≥fono para generar el audio que se debe enviar.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_1.png)

Comenzar la conversaci√≥n.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_2.png)

###Utilice la funci√≥n de chat de Gemini en el plano de trabajo.

Cree el siguiente plan, configure las opciones de Gemini, haga clic en Ejecutar y ver√° en la pantalla la informaci√≥n de chat devuelta por Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_2.png)

###Utiliza Blueprint para enviar audio con Gemini.

Crear el siguiente plan, configurar la carga de audio, ajustar las opciones de G√©minis, hacer clic en ejecutar, y ver√°s en pantalla la informaci√≥n de chat devuelta tras el procesamiento de audio por G√©minis.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_2.png)

## Deepseek

###El editor utiliza Deepseek.

Crear una nueva conversaci√≥n (New Chat), cambiar ChatApi por OpenAi y configurar los par√°metros de la API de Deepseek. Agregar un nuevo modelo candidato llamado deepseek-chat y establecer el modelo como deepseek-chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_1.png)

Iniciar conversaci√≥n.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_2.png)

###Utilizar Deepseek para chatear en Blueprint.

Cree un plan como se indica a continuaci√≥n, configure las opciones de solicitud relacionadas con Deepseek, como el Modelo, la URL base, la URL final, la clave de API, entre otros par√°metros. Haga clic en Ejecutar y ver√° en la pantalla la informaci√≥n de chat devuelta por Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_2.png)

##Nodo de funci√≥n de diagrama adicional proporcionado.

###Llama Áõ∏ÂÖ≥

"Cllama Is Valid" translates to "Cllama es v√°lido"ÔºöÂà§Êñ≠ Cllama llama.cpp ÊòØÂê¶Ê≠£Â∏∏ÂàùÂßãÂåñ"

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_1.png)

"Comprueba si llama.cpp es compatible con GPU en el entorno actual."

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_2.png)

"Obtener Soporte Backend de Llama": Obt√©n todos los backends soportados por llama.cpp actualmente.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_3.png)

"Cllama Prepare ModelFile In Pak": Copia autom√°ticamente los archivos de modelo de Pak al sistema de archivos.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_4.png)

###Im√°genes relacionadas.

"Convertir UTexture2D a Base64": Convierte la imagen de UTexture2D a formato png en Base64.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_5.png)

Guardar UTexture2D en un archivo .png.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_6.png)

Cargar archivo .png en UTexture2D: Cargar archivo .png en UTexture2D

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_7.png)

"Duplicar UTexture2D"

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_8.png)

###Audio relacionado

"Load .wav file to USoundWave": Cargar archivo .wav en USoundWave

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_9.png)

Convertir datos .wav a USoundWave: Convertir los datos binarios .wav a USoundWave.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_10.png)

Guardar USoundWave como archivo .wav

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_11.png)

"Obtener datos PCM brutos de USoundWave": Convertir USoundWave en datos binarios de audio.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_12.png)

"Convierte USoundWave a Base64"

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_13.png)

"Duplicar USoundWave"

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_14.png)

Convertir los datos de captura de audio en USoundWave: Convert Audio Capture Data to USoundWave

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_15.png)

##Registro de actualizaciones

### v1.6.0 - 2025.03.02

####Nueva funci√≥n

Actualizaci√≥n del archivo llama.cpp a la versi√≥n b4604.

Cllama supports GPU backends: cuda and metal.

La herramienta de chat Cllama es compatible con el uso de GPU.

Soporte para leer archivos de modelos empaquetados en Pak.

#### Bug Fix

Corregido el problema de fallo de Cllama al recargar durante el razonamiento.

Reparar errores de compilaci√≥n en iOS.

### v1.5.1 - 2025.01.30

####Nuevas caracter√≠sticas

* Solo se permite a Gemini enviar archivos de audio.

Optimizar el m√©todo para obtener los datos de PCM y descomprimir los datos de audio al generar B64.

Solicitud de agregar dos callbacks OnMessageFinished y OnImagesFinished.

Optimizar el M√©todo Gemini, para autom√°ticamente obtener el M√©todo seg√∫n bStream.

Agregar algunas funciones de blueprint para facilitar la conversi√≥n del Wrapper al tipo real, y obtener el mensaje de respuesta y el error.

#### Bug Fix

Reparar el problema de m√∫ltiples llamadas a Request Finish.

### v1.5.0 - 2025.01.29

####Nueva funcionalidad.

Apoyar el env√≠o de archivos de audio a Gemini.

Las herramientas del editor admiten el env√≠o de audio y grabaciones.

#### Bug Fix

Corregir el error de falla al copiar la sesi√≥n.

### v1.4.1 - 2025.01.04

####Reparaci√≥n de problemas.

La herramienta de mensajer√≠a permite enviar solo im√°genes sin incluir texto.

* Corregir el problema de env√≠o de im√°genes en la interfaz de OpenAI.

Reparar el problema omitido en la configuraci√≥n de las herramientas de chat OpanAI y Azure, que se refiere a los par√°metros Quality, Style y ApiVersion.

### v1.4.0 - 2024.12.30

####Nueva funci√≥n.

* (Funci√≥n experimental) Cllama (llama.cpp) es compatible con modelos multimodales y puede procesar im√°genes.

Todos los par√°metros de tipo de plano han sido provistos con detalles de orientaci√≥n.

### v1.3.4 - 2024.12.05

####Nueva funci√≥n

OpenAI soporta la API de visi√≥n.

####Reparaci√≥n de problemas

Corregir el error al establecer OpenAI stream=false.

### v1.3.3 - 2024.11.25

####Nueva funci√≥n

Soporta UE-5.5.

####Reparaci√≥n de problemas

Corregir el problema de que algunas partes del dise√±o no funcionen correctamente.

### v1.3.2 - 2024.10.10

####Reparaci√≥n de problemas

Reparar el fallo de cllama al detener manualmente la solicitud.

Solucionar el problema de no encontrar los archivos ggml.dll y llama.dll al empaquetar la versi√≥n de descarga de la tienda en Windows.

Crear solicitud comprueba en el hilo del juego.

### v1.3.1 - 2024.9.30

####Nueva funci√≥n

Agregar un SystemTemplateViewer que permita visualizar y utilizar cientos de plantillas de configuraci√≥n del sistema.

####Reparaci√≥n de problemas

Reparar el complemento descargado desde la tienda, llama.cpp no puede encontrar la biblioteca de v√≠nculos.

Corregir el problema de la longitud excesiva de la ruta en LLAMACpp

Reparar el error llama.dll despu√©s de empaquetar en Windows.

Corregir problema de acceso a la ruta de archivo en iOS/Android.

Corregir el error de configuraci√≥n del nombre en Cllame.

### v1.3.0 - 2024.9.23

####Importante nueva funci√≥n

Integrating la llama.cpp, supporting la ejecuci√≥n fuera de l√≠nea local de modelos grandes.

### v1.2.0 - 2024.08.20

####Nueva funci√≥n

Apoyo a OpenAI Image Edit / Image Variation

Admite la API de Ollama, admite la obtenci√≥n autom√°tica de la lista de modelos admitidos por Ollama.

### v1.1.0 - 2024.08.07

####Nueva caracter√≠stica.

Apoyo a la propuesta.

### v1.0.0 - 2024.08.05

####Nueva funci√≥n.

Funcionalidad b√°sica completa

Apoyo a OpenAI, Azure, Claude y Gemini.

Herramienta de chat con un editor integrado y funciones completas.

--8<-- "footer_es.md"


> Este mensaje ha sido traducido utilizando ChatGPT, por favor en [**feedback**](https://github.com/disenone/wiki_blog/issues/new)Se√±ale cualquier omisi√≥n. 
