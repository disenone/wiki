---
layout: post
title: Documentaci√≥n de UE para el complemento AIChatPlus
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: Documentaci√≥n de instrucciones del complemento UE AIChatPlus
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Documento de instrucciones del complemento UE AIChatPlus

##Almac√©n p√∫blico

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtener complemento.

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Introducci√≥n del complemento

Este complemento es compatible con UE5.2+.

UE.AIChatPlus es un complemento para UnrealEngine que permite la comunicaci√≥n con diversos servicios de chat AI GPT. Actualmente, soporta servicios como OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama, y llama.cpp en modo offline local. En el futuro se a√±adir√°n m√°s servicios proveedores. Su implementaci√≥n se basa en solicitudes REST as√≠ncronas para lograr un alto rendimiento, facilitando as√≠ a los desarrolladores de Unreal Engine integrar estos servicios de chat AI.

UE.AIChatPlus tambi√©n incluye una herramienta de edici√≥n que permite utilizar directamente los servicios de chat AI en el editor para generar texto e im√°genes, analizar im√°genes, entre otras funciones.

##Instrucciones de uso

###Herramienta de chat del editor.

En la barra de men√∫, selecciona Herramientas -> AIChatPlus -> AIChat para abrir la herramienta de edici√≥n de chat proporcionada por el complemento.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


El software admite generaci√≥n de texto, chat de texto, generaci√≥n de im√°genes y an√°lisis de im√°genes.

La interfaz de la herramienta es aproximadamente:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Funci√≥n principal

Modelo grande sin conexi√≥n: Integraci√≥n de la biblioteca llama.cpp que permite la ejecuci√≥n sin conexi√≥n de modelos grandes a nivel local.

Crear una nueva conversaci√≥n de texto: haz clic en el bot√≥n `Nuevo Chat` en la esquina inferior izquierda para iniciar una nueva conversaci√≥n de texto.

Generaci√≥n de im√°genes: Haz clic en el bot√≥n `New Image Chat` en la esquina inferior izquierda para iniciar una nueva sesi√≥n de generaci√≥n de im√°genes.

An√°lisis de im√°genes: Algunos servicios de chat de "New Chat" admiten el env√≠o de im√°genes, como Claude, Google Gemini. Simplemente haz clic en el bot√≥n üñºÔ∏è o üé® encima del campo de entrada para cargar la imagen que deseas enviar.

Apoyo a los planos (Blueprint): apoyo a la creaci√≥n de planos API, para llevar a cabo funciones como chat de texto, generaci√≥n de im√°genes, etc.

Establecer el personaje de chat actual: el men√∫ desplegable en la parte superior del cuadro de chat te permite seleccionar el personaje desde el cual se enviar√° el texto, lo que te permitir√° simular diferentes roles para ajustar la conversaci√≥n con la inteligencia artificial.

Vaciar conversaci√≥n: al hacer clic en la ‚ùå en la parte superior del cuadro de chat, se pueden borrar los mensajes hist√≥ricos de la conversaci√≥n actual.

Plantilla de conversaci√≥n: Incorpora cientos de configuraciones de plantillas de di√°logo para facilitar el manejo de problemas comunes.

Configuraci√≥n general: Al hacer clic en el bot√≥n `Configuraci√≥n` en la esquina inferior izquierda, se abrir√° la ventana de configuraci√≥n general. Aqu√≠ podr√°s ajustar la configuraci√≥n predeterminada para el chat de texto, los servicios de API de generaci√≥n de im√°genes y definir los par√°metros espec√≠ficos para cada servicio de API. Los ajustes se guardar√°n autom√°ticamente en la ruta del proyecto `$(CarpetaProyecto)/Guardado/AIChatPlusEditor`.

Configuraci√≥n de la conversaci√≥n: al hacer clic en el bot√≥n de configuraci√≥n en la parte superior del cuadro de chat, puedes abrir la ventana de configuraci√≥n de la conversaci√≥n actual. Permite modificar el nombre de la conversaci√≥n, el servicio API utilizado en la conversaci√≥n, as√≠ como establecer par√°metros espec√≠ficos para cada uso de API en la conversaci√≥n. La configuraci√≥n de la conversaci√≥n se guarda autom√°ticamente en `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions`.

Editar contenido del chat: al colocar el cursor sobre el contenido del chat, aparecer√° un bot√≥n de configuraci√≥n para ese contenido en particular, que permitir√° regenerar, modificar, copiar o eliminar el contenido, as√≠ como regenerar contenido debajo (para el contenido creado por el usuario).

Visor de im√°genes: Para la generaci√≥n de im√°genes, al hacer clic en una imagen se abrir√° una ventana de visualizaci√≥n de im√°genes (ImageViewer), que permite guardar la imagen como PNG/Textura UE, la cual puede ser visualizada directamente en el explorador de contenido (Content Browser) para su conveniente uso en el editor. Tambi√©n se admiten funciones como eliminar im√°genes, regenerarlas, y continuar generando m√°s im√°genes. En el editor de Windows, tambi√©n es posible copiar im√°genes directamente al portapapeles para facilitar su uso. Las im√°genes generadas en cada sesi√≥n se guardar√°n autom√°ticamente en la carpeta de cada sesi√≥n, generalmente en la ruta `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Plan:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Configuraci√≥n general:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Configuraci√≥n de conversaci√≥n:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Modificar el contenido del chat:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visualizador de im√°genes:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utilizaci√≥n de modelos grandes sin conexi√≥n.

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Plantilla de di√°logo

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Introducci√≥n al c√≥digo central.

En este momento, el complemento se divide en los siguientes m√≥dulos:

AIChatPlusCommon: M√≥dulo de tiempo de ejecuci√≥n, responsable de manejar las solicitudes enviadas a trav√©s de varias API de IA y analizar el contenido de las respuestas.

AIChatPlusEditor: M√≥dulo de editor, encargado de implementar la herramienta de chat de IA del editor.

AIChatPlusCllama: M√≥dulo de tiempo de ejecuci√≥n (Runtime), encargado de encapsular la interfaz y par√°metros de llama.cpp, para llevar a cabo la ejecuci√≥n sin conexi√≥n de grandes modelos.

Thirdparty/LLAMACpp: M√≥dulo de terceros en tiempo de ejecuci√≥n que integra la biblioteca din√°mica y los archivos de encabezado de llama.cpp.

El UClass responsable espec√≠fico de enviar la solicitud es FAIChatPlus_xxxChatRequest, cada servicio API tiene su propio UClass de solicitud independiente. Las respuestas de la solicitud se obtienen a trav√©s de UAIChatPlus_ChatHandlerBase / UAIChatPlus_ImageHandlerBase dos UClass, solo es necesario registrar el delegado de devoluci√≥n de llamada correspondiente.

Antes de enviar la solicitud, es necesario configurar los par√°metros API y el mensaje a enviar. Esto se hace a trav√©s de FAIChatPlus_xxxChatRequestBody. El contenido espec√≠fico de la respuesta tambi√©n se analiza en FAIChatPlus_xxxChatResponseBody, y al recibir la devoluci√≥n se puede obtener el ResponseBody a trav√©s de una interfaz espec√≠fica.

Puedes encontrar m√°s detalles del c√≥digo fuente en la tienda de UE: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

## Cllama(llama.cpp)

###Utiliza la herramienta del editor para trabajar con el modelo sin conexi√≥n Cllama(llama.cpp).

A continuaci√≥n se explica c√≥mo utilizar el modelo fuera de l√≠nea llama.cpp en la herramienta de edici√≥n AIChatPlus.

Primero, descarga el modelo sin conexi√≥n desde el sitio web de HuggingFace: [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Coloque el modelo en una carpeta espec√≠fica, por ejemplo, en el directorio Content/LLAMA del proyecto del juego.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

Abre la herramienta de edici√≥n AIChatPlus: Herramientas -> AIChatPlus -> AIChat, crea una nueva sesi√≥n de chat y accede a la p√°gina de configuraci√≥n de la sesi√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Configura la API como Cllama, activa la Configuraci√≥n Personalizada de la API, a√±ade la ruta de b√∫squeda de modelos y selecciona el modelo.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

Comenzar la conversaci√≥n!!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###Utiliza la herramienta del editor para procesar im√°genes con el modelo fuera de l√≠nea Cllama(llama.cpp).

Descarga el modelo MobileVLM_V2-1.7B-GGUF de HuggingFace y col√≥calo en el directorio Content/LLAMA bajo el nombre [ggml-model-q4_k.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/ggml-model-q4_k.gguf)Âíå [mmproj-model-f16.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/mmproj-model-f16.gguf)Lo siento, no hay texto para traducir. ¬øHay algo m√°s en lo que pueda ayudarte?

Configura el modelo de la sesi√≥n:

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_1.png)

Enviar una imagen para comenzar la conversaci√≥n.

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_2.png)

###El c√≥digo utiliza el modelo fuera de l√≠nea Cllama (llama.cpp).

Estas indicaciones muestran c√≥mo utilizar el modelo offline llama.cpp en el c√≥digo.

Primero, tambi√©n debes descargar el archivo del modelo en Content/LLAMA.

Agregar una orden al c√≥digo para enviar un mensaje al modelo sin conexi√≥n dentro de esa orden.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

Despu√©s de recompilar, simplemente utiliza el comando en el editor Cmd y podr√°s ver los resultados de la gran modelo en el registro OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###El uso del modelo fuera de l√≠nea del plano se llama llama.cpp.

Translate these text into Spanish language:

C√≥mo usar el modelo fuera de l√≠nea llama.cpp en un diagrama de conector.

En el diagrama, haz clic derecho para crear un nodo llamado `Enviar solicitud de chat de Cllama`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

Cree un nodo Options y establezca `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

Crear mensajes, agregar un mensaje del sistema y un mensaje del usuario.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Crear un Delegado que reciba la informaci√≥n de salida del modelo y la imprima en la pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

La traducci√≥n al espa√±ol es la siguiente:

* La apariencia de un blueprint completo es la siguiente, activa el blueprint y podr√°s ver en la pantalla del juego el mensaje devuelto al imprimir el modelo grande.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

###El archivo llama.cpp utiliza la GPU.

Agregar la opci√≥n "Num Gpu Layer" a "Cllama Chat Request Options" para configurar la carga de GPU en llama.cpp, como se muestra en la imagen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_1.png)

Puedes usar nodos de blueprints para determinar si el entorno actual es compatible con GPU y obtener los backends compatibles con dicho entorno.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_2.png)

###Procesar archivos de modelos en el archivo .Pak despu√©s de la empaquetaci√≥n.

Una vez que se crea el archivo Pak, todos los recursos del proyecto se almacenan en el archivo .Pak, incluyendo los archivos gguf del modelo sin conexi√≥n.

Debido a que llama.cpp no puede leer directamente archivos .Pak, es necesario copiar los archivos de modelos fuera del archivo .Pak en el sistema de archivos.

AIChatPlus ofrece una funci√≥n que autom√°ticamente copia y procesa los archivos de modelos dentro de un archivo .Pak, y los guarda en la carpeta Saved:

![guide bludprint](assets/img/2024-ue-aichatplus/guide_cllama_gpu_3.png)

O puedes manejar los archivos de modelo en .Pak t√∫ mismo, lo importante es copiar y procesar los archivos, ya que llama.cpp no puede leer correctamente .Pak.

## OpenAI

###El editor utiliza el chat de OpenAI.

Abre la herramienta de chat Tools -> AIChatPlus -> AIChat, crea una nueva conversaci√≥n New Chat, establece la sesi√≥n ChatApi en OpenAI, configura los par√°metros de la interfaz

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_1.png)

Iniciar chat:

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_2.png)

Cambiar el modelo a gpt-4o / gpt-4o-mini permitir√° utilizar la funci√≥n de an√°lisis visual de OpenAI en las im√°genes.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_3.png)

###El editor utiliza OpenAI para trabajar con im√°genes (crear/modificar/variar).

Crear una nueva conversaci√≥n de imagen en la herramienta de chat, etiquetarla como OpenAI y ajustar la configuraci√≥n seg√∫n sea necesario.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_1.png)

Crear imagen

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_2.png)

Modificar la imagen cambiando el tipo de chat de la imagen a "Editar", luego subir dos im√°genes: una imagen original y otra donde la m√°scara muestre las √°reas que necesitan ser modificadas (donde el canal alfa es 0).

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_4.png)

Modificar el tipo de chat de imagen a "Variation" y subir una imagen. OpenAI devolver√° una variante de la imagen original.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_5.png)

###Utilizando el modelo de OpenAI para chatear con el plano de ejecuci√≥n.

En el mapa, haz clic derecho para crear un nodo llamado `Enviar solicitud de chat de OpenAI en el mundo`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_1.png)

Crear el nodo de opciones y establecer `Stream=true, Api Key="tu clave de API de OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_2.png)

Crear mensajes, a√±adir un mensaje del sistema y un mensaje de usuario respectivamente.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Crear un delegado para recibir la informaci√≥n de salida del modelo y mostrarla en pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

La versi√≥n completa del plan se ve as√≠, ejecuta el plan y podr√°s ver en la pantalla del juego el mensaje devuelto al imprimir el modelo grande.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_4.png)

###Utilizando OpenAI para crear im√°genes.

En el panel de control, haz clic derecho para crear un nodo 'Send OpenAI Image Request' y configura 'In Prompt="una hermosa mariposa"'.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_1.png)

Crea un nodo Options y establece `Api Key="tu clave de API de OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_2.png)

Asociar el evento "On Images" y guardar las im√°genes en el disco duro local.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_3.png)

La apariencia de un plano detallado completo es esta, al ejecutar el programa, podr√°s ver la imagen guardada en la ubicaci√≥n especificada.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_5.png)

## Azure

###El editor utiliza Azure.

Crear nueva conversaci√≥n (New Chat), cambiar ChatApi a Azure y establecer los par√°metros de la Api de Azure.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_1.png)

Comenzar la conversaci√≥n

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_2.png)

###Utilizar Azure para crear im√°genes en el editor.

Crear una nueva sesi√≥n de chat de im√°genes (New Image Chat), cambiar ChatApi a Azure y configurar los par√°metros de la API de Azure. Ten en cuenta que, si se trata del modelo dall-e-2, es necesario establecer los par√°metros Quality y Stype en not_use.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_1.png)

Comience la conversaci√≥n para que Azure cree la imagen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_2.png)

###Utilizando Azure Chat para el Blueprint.

Crea el siguiente dise√±o, configura las opciones de Azure, haz clic en Ejecutar y ver√°s en pantalla la informaci√≥n de chat que Azure devuelve.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_2.png)

###Utilizando Azure para crear im√°genes de manera profesional.

Establezca el plan detallado a continuaci√≥n, configure las opciones de Azure, haga clic en "Ejecutar". Si la creaci√≥n de la imagen tiene √©xito, ver√° el mensaje "Imagen creada" en la pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_image_1.png)

Seg√∫n la configuraci√≥n del esquema anterior, la imagen se guardar√° en la ruta D:\Descargas\mariposa.png

## Claude

###El editor utiliza a Claude para chatear y analizar im√°genes.

Crear nueva conversaci√≥n (Nuevo Chat), cambiar ChatApi a Claude y configurar los par√°metros de la API de Claude.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_1.png)

Comenzar a chatear

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_2.png)

###Utilizando Blueprint para chatear y analizar im√°genes con Claude.

En el plano, haz clic derecho para crear un nodo llamado `Enviar solicitud de chat a Claude`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_1.png)

Crear un nodo de opciones y configurar `Stream=true, Api Key="tu clave de API de Clude", Max Output Tokens=1024`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_2.png)

Crear mensajes, crear una Texture2D desde un archivo, y luego usar esa Texture2D para crear un AIChatPlusTexture, y finalmente agregar ese AIChatPlusTexture al mensaje.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_3.png)

Sigue el tutorial mencionado para crear un evento y mostrar la informaci√≥n en la pantalla del juego.

La interpretaci√≥n del texto ser√≠a la siguiente:

* La apariencia completa del blueprint es as√≠, al ejecutar el blueprint, se puede ver en la pantalla del juego el mensaje de retorno de la impresi√≥n de un gran modelo.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_5.png)

## Ollama

###Obtener Ollama

Puedes descargar el paquete de instalaci√≥n localmente desde el sitio web oficial de Ollama: [ollama.com](https://ollama.com/)

Se puede usar Ollama a trav√©s de la interfaz Ollama proporcionada por otros.

###El editor utiliza Ollama para chatear y analizar im√°genes.

Por favor traduzca el texto al espa√±ol:

* Êñ∞Âª∫‰ºöËØùÔºàNew ChatÔºâÔºåÊää ChatApi Êîπ‰∏∫ OllamaÔºåÂπ∂ËÆæÁΩÆ Ollama ÁöÑ Api ÂèÇÊï∞„ÄÇÂ¶ÇÊûúÊòØÊñáÊú¨ËÅäÂ§©ÔºåÂàôËÆæÁΩÆÊ®°Âûã‰∏∫ÊñáÊú¨Ê®°ÂûãÔºåÂ¶Ç llama3.1ÔºõÂ¶ÇÊûúÈúÄË¶ÅÂ§ÑÁêÜÂõæÁâáÔºåÂàôËÆæÁΩÆÊ®°Âûã‰∏∫ÊîØÊåÅ vision ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç moondream„ÄÇ

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_1.png)

Comenzar a chatear

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_2.png)

###Utilizando Ollama, la aplicaci√≥n permite chatear y analizar im√°genes.

Crear el siguiente plan, configurar las Ollama Options, hacer clic en ejecutar y ver√°s la informaci√≥n de chat devuelta por Ollama impresa en la pantalla.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_2.png)

## Gemini

###Utilizar Gemini en el editor.

Crear nuevo chat, cambiar ChatApi a Gemini y configurar los par√°metros de la API de Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_1.png)

Iniciar chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_2.png)

###El editor utiliza Gemini para enviar el audio.

Seleccionar entre leer el audio desde un archivo / desde un recurso / grabarlo desde el micr√≥fono, para generar el audio que se desea enviar.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_1.png)

Iniciar el chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_2.png)

###Utilizar el chat Gemini en Blueprints.

Crear el siguiente plan, configurar las Opciones de Gemini, hacer clic en Ejecutar y ver√°s en la pantalla la informaci√≥n de chat devuelta por Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_2.png)

###Utilizando Gemini, se env√≠a el audio del plano.

Crea el siguiente plan, configura la carga de audio, establece las opciones de Gemini, haz clic en ejecutar y ver√°s en pantalla la informaci√≥n de chat devuelta despu√©s de que Gemini haya procesado el audio.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_2.png)

## Deepseek

###El editor utiliza Deepseek.

Crear una nueva conversaci√≥n (New Chat), cambiar ChatApi por OpenAi y configurar los par√°metros de la API de Deepseek. Agregar un nuevo modelo de candidato llamado deepseek-chat y configurar el modelo como deepseek-chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_1.png)

Comenzar la conversaci√≥n.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_2.png)

###Utilizar el chat Deepseek en Blueprint.

Crea el siguiente esquema, configura las Opciones de Solicitud relacionadas con Deepseek, incluyendo Modelo, URL base, URL de punto final, ApiKey, entre otros par√°metros. Haz clic en ejecutar y podr√°s ver en pantalla la informaci√≥n de chat devuelta por Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_2.png)

##Nodo de funci√≥n adicional proporcionado en el plano de dise√±o.

###Llama Áõ∏ÂÖ≥

"La llama de Cllama es v√°lida": Determine si Cllama llama.cpp est√° inicializado correctamente

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_1.png)

"Comprueba si llama.cpp es compatible con el backend de GPU en el entorno actual".

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_2.png)

"Obtener Soporte de Backends de Llama": Obtener todos los backends compatibles con llama.cpp actuales.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_3.png)

"Preparar archivo de modelo de Cllama en Pak": Autom√°ticamente copia los archivos de modelo en Pak al sistema de archivos.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_4.png)

###Imagen relacionada

"Convertir UTexture2D a Base64": Convertir la imagen de UTexture2D en formato base64 PNG.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_5.png)

Guardar UTexture2D en un archivo .png.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_6.png)

"Cargar archivo .png en UTexture2D": Cargar archivo .png en UTexture2D

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_7.png)

"Duplicar UTexture2D"

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_8.png)

###Audio-related.

Cargar archivo .wav en USoundWave.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_9.png)

"Convertir datos .wav a USoundWave": Convertir datos binarios .wav a USoundWave

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_10.png)

Guardar USoundWave en un archivo .wav.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_11.png)

Obtener datos PCM sin procesar de USoundWave: Convierte USoundWave en datos binarios de audio.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_12.png)

"Convertir USoundWave a Base64": Convertir USoundWave a datos Base64

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_13.png)

"Duplicar USoundWave": Duplicar USoundWave

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_14.png)

"Convertir datos de captura de audio a USoundWave": Convert Audio Capture ÂΩïÈü≥Êï∞ÊçÆËΩ¨Êàê USoundWave

![guide bludprint](assets/img/2024-ue-aichatplus/guide_util_15.png)

##Registro de actualizaciones

### v1.6.0 - 2025.03.02

####Nueva caracter√≠stica.

Actualizaci√≥n del archivo llama.cpp a la versi√≥n b4604.
Cllama supports GPU backends: cuda and metal.
La herramienta de chat Cllama es compatible con el uso de GPU.
Soportar la lectura de archivos de modelo empaquetados en Pak.

#### Bug Fix

Corregir el problema de Cllama que provocaba que se bloqueara al recargar durante la deducci√≥n.

Reparar error de compilaci√≥n en iOS.

### v1.5.1 - 2025.01.30

####Nueva caracter√≠stica

Solo se permite el env√≠o de audio a trav√©s de Gemini.

Optimizamos el m√©todo para obtener PCMData, descomprimiendo los datos de audio al generar B64.

Solicitar agregar dos funciones de callback OnMessageFinished y OnImagesFinished.

Optimizar el M√©todo Gemini para obtener autom√°ticamente el M√©todo bas√°ndose en bStream.

Agregar algunas funciones de blueprint para facilitar la conversi√≥n de Wrapper a tipos reales, y obtener el Mensaje de Respuesta y el Error.

#### Bug Fix

Corregir el problema de m√∫ltiples llamadas a Request Finish.

### v1.5.0 - 2025.01.29

####Nueva caracter√≠stica

Apoyar el env√≠o de audio a Gemini.

Las herramientas del editor admiten el env√≠o de audio y grabaciones.

#### Bug Fix

Corregir el error de copia fallida de la sesi√≥n.

### v1.4.1 - 2025.01.04

####Reparaci√≥n de problemas

La herramienta de chat admite enviar solo im√°genes sin texto.

Reparar problema de env√≠o de im√°genes en la interfaz de OpenAI.

Reparar el problema de par√°metros faltantes Quality, Style, ApiVersion en la configuraci√≥n de herramientas de chat OpanAI y Azure.

### v1.4.0 - 2024.12.30

####Nueva caracter√≠stica

* (Funci√≥n experimental) Cllama (llama.cpp) admite modelos multimodales y puede procesar im√°genes.

Se han a√±adido indicaciones detalladas a todos los par√°metros de tipo Blueprint.

### v1.3.4 - 2024.12.05

####Nueva caracter√≠stica.

OpenAI admite la API de visi√≥n.

####Reparaci√≥n de problemas

Reparar el error al establecer OpenAI stream=false.

### v1.3.3 - 2024.11.25

####Nueva caracter√≠stica.

Compatibilidad con UE-5.5.

####Reparaci√≥n de problemas

Corregir el problema de que algunas partes del plano no funcionen.

### v1.3.2 - 2024.10.10

####Reparaci√≥n de problemas

Reparar el bloqueo de la aplicaci√≥n cuando se detiene la solicitud manualmente.

Solucionar el problema de no encontrar los archivos ggml.dll y llama.dll al empaquetar la versi√≥n de descarga de Win en la tienda.

Crear solicitud y verificar si est√° en el hilo del juego.

### v1.3.1 - 2024.9.30

####Nueva funci√≥n

Agregar un SystemTemplateViewer, que permite visualizar y utilizar cientos de plantillas de configuraci√≥n del sistema.

####Reparaci√≥n de problemas

Reparar el plugin descargado desde la tienda, no se encuentra la biblioteca de enlace llama.cpp.

Corregido el problema de la longitud excesiva de la ruta en LLAMACpp.

Reparar el error de enlace de llama.dll despu√©s de empaquetar en Windows.

Corregir el problema de lectura de la ruta del archivo en iOS/Android.

Repare el error al establecer el nombre de la llamada.

### v1.3.0 - 2024.9.23

####Importante nueva caracter√≠stica

Integraci√≥n de llama.cpp para permitir la ejecuci√≥n offline de modelos grandes en el entorno local.

### v1.2.0 - 2024.08.20

####Nueva funcionalidad.

Apoyo a OpenAI Image Edit/Image Variation

Admite la API de Ollama, admite la obtenci√≥n autom√°tica de la lista de modelos admitidos por Ollama.

### v1.1.0 - 2024.08.07

####Nueva funci√≥n

Apoyo de la propuesta.

### v1.0.0 - 2024.08.05

####Nueva caracter√≠stica.

Funcionalidad b√°sica completa

Apoyo a OpenAI, Azure, Claude, Gemini.

Herramienta de chat con editor integrado y funciones completas.

--8<-- "footer_es.md"


> Este mensaje ha sido traducido utilizando ChatGPT, por favor [**ÂèçÈ¶à**](https://github.com/disenone/wiki_blog/issues/new)Se√±alar cualquier omisi√≥n. 
