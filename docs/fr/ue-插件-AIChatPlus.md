---
layout: post
title: Document d'instructions du plug-in UE AIChatPlus
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: UE Plugin AIChatPlus Documentation
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#Document de description du plugin UE AIChatPlus

##Entrep√¥t public.

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Obtenir le plugin

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Pr√©sentation du module compl√©mentaire

Ce plugin est compatible avec UE5.2 et les versions ult√©rieures.

UE.AIChatPlus is a plugin for UnrealEngine that enables communication with various GPT AI chat services. Currently, it supports services such as OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama, and local offline llama.cpp. More service providers will be supported in the future. Its implementation is based on asynchronous REST requests, providing high efficiency and convenient access to these AI chat services for UnrealEngine developers.

En m√™me temps, UE.AIChatPlus comprend √©galement un outil d'√©dition qui permet d'utiliser directement ces services de chat AI dans l'√©diteur, de g√©n√©rer des textes et des images, d'analyser des images, etc.

##Instructions d'utilisation

###Outil de messagerie de l'√©diteur

Le menu Outils -> AIChatPlus -> AIChat ouvre l'outil de chat de l'√©diteur fourni par le plugin.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


Le logiciel prend en charge la g√©n√©ration de texte, le chat textuel, la g√©n√©ration d'images et l'analyse d'images.

L'interface de l'outil est en gros :

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Fonctionnalit√©s principales

Mod√®le hors ligne : Int√©gration de la biblioth√®que llama.cpp pour prendre en charge l'ex√©cution hors ligne locale des mod√®les volumineux.

* Chat textuel : Cliquez sur le bouton `New Chat` dans le coin inf√©rieur gauche pour cr√©er une nouvelle session de chat textuel.

G√©n√©ration d'images : Appuyez sur le bouton `New Image Chat` situ√© en bas √† gauche pour d√©marrer une nouvelle session de g√©n√©ration d'images.

Analyse d'image : Certaines fonctionnalit√©s de chat de "New Chat" prennent en charge l'envoi d'images, telles que Claude, Google Gemini. Cliquez sur l'ic√¥ne üñºÔ∏è ou üé® au-dessus de la zone de texte pour charger l'image √† envoyer.

Soutien aux plans (Blueprint) : Soutien √† la cr√©ation de plans pour API, r√©alisation de chat texte, g√©n√©ration d'images, etc.

D√©finissez le r√¥le de conversation actuel : Le menu d√©roulant en haut de la bo√Æte de discussion permet de choisir le r√¥le depuis lequel les messages sont envoy√©s, ce qui permet de simuler diff√©rents r√¥les pour ajuster la conversation avec l'IA.

Vider la conversation : Le bouton ‚ùå en haut de la bo√Æte de chat permet d'effacer l'historique des messages de la conversation en cours.

* Mod√®les de dialogue : des centaines de mod√®les de param√®tres de dialogue int√©gr√©s, facilitant le traitement des questions courantes.

Param√®tres globaux : En cliquant sur le bouton `Param√®tres` en bas √† gauche, vous pouvez ouvrir la fen√™tre des param√®tres globaux. Vous pouvez d√©finir le chat texte par d√©faut, le service d'API de g√©n√©ration d'images, et configurer les param√®tres sp√©cifiques de chaque service API. Les param√®tres seront automatiquement enregistr√©s dans le chemin du projet `$(DossierProjet)/Saved/AIChatPlusEditor`.

Param√®tres de la conversation : en cliquant sur le bouton de param√®tres en haut de la bo√Æte de chat, vous pouvez ouvrir la fen√™tre de param√®tres de la conversation actuelle. Vous pouvez modifier le nom de la conversation, le service API utilis√© pour la conversation, ainsi que les param√®tres sp√©cifiques de l'API utilis√©s pour chaque session individuelle. Les param√®tres de la conversation sont automatiquement enregistr√©s dans `$(DossierDuProjet)/Saved/AIChatPlusEditor/Sessions`.

* Modification du contenu de chat : Survolez le contenu du chat avec la souris pour faire appara√Ætre le bouton de r√©glage du contenu, qui permet de r√©g√©n√©rer le contenu, de le modifier, de le copier, de le supprimer, ou de le r√©g√©n√©rer en bas (pour le contenu dont le r√¥le est utilisateur).

* Navigation d'images : Pour la g√©n√©ration d'images, cliquer sur une image ouvrira la fen√™tre de visualisation d'images (ImageViewer), permettant d'enregistrer l'image sous PNG/UE Texture. La texture peut √™tre directement visualis√©e dans le navigateur de contenu (Content Browser), facilitant son utilisation dans l'√©diteur. De plus, il est possible de supprimer l'image, de la r√©g√©n√©rer ou de g√©n√©rer davantage d'images. Pour l'√©diteur sous Windows, la fonction de copier l'image est √©galement disponible, permettant de la copier directement dans le presse-papiers pour une utilisation pratique. Les images g√©n√©r√©es pendant la session seront automatiquement enregistr√©es dans chaque dossier de session, avec un chemin g√©n√©ralement situ√© √† `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Plan :

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Param√®tres g√©n√©raux :

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Param√®tres de conversation :

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Change the chat content:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Visionneuse d'images :

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Utiliser un mod√®le volumineux hors ligne

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Mod√®le de dialogue

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Pr√©sentation du code source principal

Actuellement, le plugin se divise en plusieurs modules :

* AIChatPlusCommon: Module d'ex√©cution (Runtime) responsable du traitement des demandes envoy√©es par diverses interfaces API AI et de l'analyse des r√©ponses.

AIChatPlusEditor: Module d'√©dition, responsable de la mise en ≈ìuvre de l'outil de discussion AI de l'√©diteur.

AIChatPlusCllama: Module d'ex√©cution (Runtime) charg√© d'encapsuler les interfaces et les param√®tres de llama.cpp, permettant ainsi d'ex√©cuter de grands mod√®les hors ligne.

* Thirdparty/LLAMACpp : Module tiers √† l'ex√©cution (Runtime), int√©grant la biblioth√®que dynamique et les fichiers d'en-t√™te de llama.cpp.

La classe UClass responsable de l'envoi des requ√™tes est FAIChatPlus_xxxChatRequest, chaque service API dispose d'une UClass Request distincte. Les r√©ponses aux requ√™tes peuvent √™tre r√©cup√©r√©es via deux UClass : UAIChatPlus_ChatHandlerBase et UAIChatPlus_ImageHandlerBase, il suffit de s'inscrire aux d√©l√©gu√©s de rappel correspondants.

Avant d'envoyer une requ√™te, il est n√©cessaire de configurer les param√®tres de l'API et le message √† envoyer, ce qui se fait via FAIChatPlus_xxxChatRequestBody. Le contenu sp√©cifique de la r√©ponse est √©galement analys√© dans FAIChatPlus_xxxChatResponseBody, et lors de la r√©ception du rappel, il est possible d'obtenir le ResponseBody via une interface sp√©cifique.

Plus de d√©tails sur le code source peuvent √™tre obtenus dans le magasin UE : [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

## Cllama(llama.cpp)

###Utilisation de l'outil d'√©diteur avec le mod√®le hors ligne Cllama (llama.cpp)

Voici comment utiliser le mod√®le hors ligne llama.cpp dans l'outil d'√©dition AIChatPlus.

* Tout d'abord, t√©l√©chargez le mod√®le hors ligne depuis le site HuggingFace : [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

* Placez le mod√®le dans un dossier, par exemple dans le r√©pertoire du projet de jeu Content/LLAMA.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

* Ouvrir l'outil d'√©dition AIChatPlus : Outils -> AIChatPlus -> AIChat, cr√©er une nouvelle session de chat et ouvrir la page de param√®tres de session.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

D√©finissez l'API sur Cllama, activez les param√®tres d'API personnalis√©s, ajoutez un chemin de recherche de mod√®le et s√©lectionnez un mod√®le.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

Commencer la conversation !!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###L'outil d'√©dition utilise le mod√®le hors ligne Cllama (llama.cpp) pour traiter les images.

T√©l√©chargez le mod√®le hors ligne MobileVLM_V2-1.7B-GGUF depuis le site web de HuggingFace et placez-le dans le r√©pertoire Content/LLAMA sous le nom [ggml-model-q4_k.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/ggml-model-q4_k.gguf)Translatez ce texte en langue fran√ßaise :

 Âíå [mmproj-mod√®le-f16.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/mmproj-model-f16.gguf)„ÄÇ

D√©finir le mod√®le de la session :

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_1.png)

* Envoyer une image pour commencer √† discuter

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_2.png)

###Le code utilise le mod√®le hors ligne Cllama (llama.cpp).

Voici comment utiliser le mod√®le hors ligne llama.cpp dans le code.

Tout d'abord, il est √©galement n√©cessaire de t√©l√©charger les fichiers de mod√®le dans Content/LLAMA.

* Modifier le code pour ajouter une commande et envoyer un message au mod√®le hors ligne dans cette commande.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

* Apr√®s avoir recompil√©, utilisez la commande dans l'√©diteur Cmd pour voir les r√©sultats de sortie du grand mod√®le dans le journal OutputLog.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###Le plan utilise le mod√®le hors ligne llama.cpp.

Explique comment utiliser le mod√®le hors ligne llama.cpp dans le blueprint.

* Dans le blueprint, faites un clic droit pour cr√©er un n≈ìud `Send Cllama Chat Request`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

* Cr√©ez le n≈ìud Options et d√©finissez `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

Cr√©ez des messages, ajoutez respectivement un message syst√®me et un message utilisateur.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

* Cr√©er un d√©l√©gu√© pour recevoir les sorties du mod√®le et les afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

La version compl√®te du blueprint ressemble √† ceci, en ex√©cutant le blueprint, vous pouvez voir le message renvoy√© √† l'√©cran de jeu imprimant le grand mod√®le.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

## OpenAI

###Le logiciel utilise OpenAI pour discuter.

Ouvrez l'outil de discussion Outils -> AIChatPlus -> AIChat, cr√©ez une nouvelle session de discussion Nouvelle discussion, d√©finissez la session ChatApi sur OpenAI, d√©finissez les param√®tres de l'interface.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_1.png)

Commencer la conversation :

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_2.png)

Changer le mod√®le en gpt-4o / gpt-4o-mini permet d'utiliser la fonction d'analyse d'images d'OpenAI.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_3.png)

###√âditeur utilisant OpenAI pour traiter les images (cr√©er/modifier/varier)

Cr√©ez une nouvelle discussion d'image dans l'outil de messagerie, nommez-la New Image Chat, ajustez les param√®tres de la discussion √† OpenAI et configurez-les.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_1.png)

Cr√©er une image

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_2.png)

* Modifiez l'image en changeant le type de conversation Image Chat en Edit, puis t√©l√©chargez deux images : l'une est l'image originale et l'autre est le masque, o√π les zones transparentes (canal alpha √† 0) indiquent les endroits √† modifier.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_4.png)

Modifier l'image en changeant le type d'image en "Variation", puis t√©l√©verser une image. OpenAI renverra une variation de l'image d'origine.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_5.png)

###Utilisation du mod√®le de conversation OpenAI dans Blueprints

* Faites un clic droit dans le blueprint pour cr√©er un n≈ìud `Send OpenAI Chat Request In World`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_1.png)

Cr√©ez un n≈ìud Options et d√©finissez `Stream=true, Api Key="your api key from OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_2.png)

Cr√©ez des messages, ajoutez respectivement un message syst√®me et un message utilisateur.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

* Cr√©er un Delegate pour recevoir les informations de sortie du mod√®le et les afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Le texte en fran√ßais est le suivant :

* Le plan complet ressemble √† ceci, en ex√©cutant le plan, vous verrez le message renvoy√© √† l'√©cran de jeu pour imprimer le grand mod√®le.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_4.png)

###Le plan utilise OpenAI pour cr√©er des images.

* Faites un clic droit sur le blueprint pour cr√©er un n≈ìud `Send OpenAI Image Request` et d√©finissez `In Prompt="a beautiful butterfly"`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_1.png)

Cr√©ez un n≈ìud Options et d√©finissez `Api Key="votre cl√© API provenant d'OpenAI"`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_2.png)

* Lier l'√©v√©nement On Images et enregistrer les images sur le disque dur local.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_3.png)

Voici √† quoi ressemble le plan complet : ex√©cutez-le pour voir l'image sauvegard√©e √† l'emplacement sp√©cifi√©.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_5.png)

## Azure

###Le logiciel utilise Azure.

Cr√©ez une nouvelle discussion (New Chat), remplacez ChatApi par Azure, et configurez les param√®tres de l'API Azure.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_1.png)

* Commencer la conversation

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_2.png)

###Utilisateur du logiciel cr√©e des images en utilisant Azure.

* Nouvelle session d'image (New Image Chat), changez ChatApi en Azure et configurez les param√®tres de l'API Azure. Notez que si le mod√®le est dall-e-2, il faut r√©gler les param√®tres Quality et Stype sur not_use.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_1.png)

* Commencez √† discuter, laissez Azure cr√©er une image.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_2.png)

###Plan utilise le chat Azure

Cr√©ez le blueprint suivant, configurez les options Azure, puis cliquez sur Ex√©cuter pour voir les messages de chat renvoy√©s par Azure s'afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_2.png)

###Cr√©er une image avec Azure selon le plan.

Cr√©ez le sch√©ma suivant, configurez les options Azure, puis appuyez sur Ex√©cuter. Si la cr√©ation de l'image est r√©ussie, un message "Create Image Done" s'affichera √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_image_1.png)

Selon les param√®tres du plan ci-dessus, l'image sera enregistr√©e √† l'emplacement D:\Dwnloads\butterfly.png.

## Claude

###Le r√©dacteur utilise Claude pour discuter et analyser des images.

Cr√©ez une nouvelle conversation (New Chat), remplacez ChatApi par Claude, et configurez les param√®tres API de Claude.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_1.png)

Commencer la discussion

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_2.png)

###Utiliser Blueprint pour discuter et analyser des images avec Claude.

* Faites un clic droit sur le blueprint pour cr√©er un n≈ìud `Send Claude Chat Request`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_1.png)

Cr√©ez un n≈ìud Options et d√©finissez `Stream=true, Api Key="votre cl√© API provenant de Clude", Max Output Tokens=1024`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_2.png)

* Cr√©ez des Messages, cr√©ez un Texture2D √† partir d'un fichier, et cr√©ez un AIChatPlusTexture √† partir du Texture2D, puis ajoutez l'AIChatPlusTexture au Message.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_3.png)

* Comme dans le tutoriel ci-dessus, cr√©ez un √©v√©nement et affichez les informations √† l'√©cran du jeu.

* Le plan complet ressemble √† ceci : en ex√©cutant le plan, vous verrez l'√©cran de jeu afficher les messages renvoy√©s par le grand mod√®le.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_5.png)

## Ollama

###Obtenir Ollama

* Vous pouvez obtenir le package d'installation pour une installation locale sur le site officiel d'Ollama : [ollama.com](https://ollama.com/)

* Ollama peut √™tre utilis√© via l'interface Ollama fournie par d'autres personnes.

###L'√©diteur utilise Ollama pour discuter et analyser des images.

* Nouvelle conversation (New Chat), changez ChatApi en Ollama et d√©finissez les param√®tres de l'Api d'Ollama. S'il s'agit d'un chat textuel, d√©finissez le mod√®le sur un mod√®le textuel, comme llama3.1 ; si vous devez traiter des images, d√©finissez le mod√®le sur un mod√®le compatible avec la vision, comme moondream.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_1.png)

* Commencer √† discuter

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_2.png)

###Utilisez Ollama pour discuter et analyser des images.

Cr√©ez le plan suivant, configurez les options d'Ollama, cliquez sur "Ex√©cuter" et vous verrez les messages de chat retourn√©s par Ollama s'afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_2.png)

## Gemini

###L'√©diteur utilise Gemini.

* Nouvelle conversation (New Chat), changez ChatApi en Gemini et param√©trez les param√®tres de l'API de Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_1.png)

* Commencer la conversation

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_2.png)

###L'√©diteur utilise Gemini pour envoyer des audio.

Lire l'audio depuis un fichier / lire l'audio depuis des ressources / enregistrer l'audio depuis un microphone, et g√©n√©rer l'audio √† envoyer.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_1.png)

Commencer la conversation

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_2.png)

###Utilisez Gemini pour discuter des plans avec les Blueprints.

Cr√©ez le plan suivant, configurez bien les options Gemini, cliquez sur ex√©cuter et vous pourrez voir les informations de chat retourn√©es par Gemini affich√©es √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_2.png)

###Le plan utilise Gemini pour envoyer de l'audio.

Cr√©ez le blueprint suivant, configurez le chargement de l'audio, param√©trez correctement les options Gemini, cliquez sur ex√©cuter, et vous verrez les informations de chat retourn√©es par Gemini apr√®s le traitement de l'audio s'afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_2.png)

## Deepseek

###L'√©diteur utilise Deepseek.

Cr√©ez une nouvelle conversation (New Chat), remplacez ChatApi par OpenAi, et configurez les param√®tres Api de Deepseek. Ajoutez un nouveau mod√®le de candidat appel√© deepseek-chat, et d√©finissez le mod√®le comme deepseek-chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_1.png)

Commencer la discussion

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_2.png)

###Utilisez Deepseek pour discuter des plans.

Cr√©ez le plan suivant, configurez les options de requ√™te li√©es √† Deepseek, y compris le mod√®le, l'URL de base, l'URL du point de terminaison, la cl√© API et d'autres param√®tres. Cliquez sur Ex√©cuter pour voir les informations de chat renvoy√©es par Gemini s'afficher √† l'√©cran.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_2.png)

##Journal des mises √† jour

### v1.5.1 - 2025.01.30

####Nouvelle fonctionnalit√©

* Seul Gemini est autoris√© √† √©mettre des audio.

* Optimiser la m√©thode d'obtention des PCMData, d√©compresser les donn√©es audio au moment de g√©n√©rer le B64.

Ajouter deux rappels OnMessageFinished et OnImagesFinished √† la demande

Optimisez la m√©thode Gemini pour obtenir automatiquement la m√©thode en fonction de bStream.

Ajoutez quelques fonctions de blueprint pour faciliter la conversion du Wrapper en type r√©el, et pour obtenir le message de r√©ponse et les erreurs.

#### Bug Fix

* Corriger le probl√®me d'appels multiples de Request Finish

### v1.5.0 - 2025.01.29

####Nouvelle fonctionnalit√©

Soutenir l'envoi audio √† Gemini.

* Les outils de l'√©diteur prennent en charge l'envoi audio et d'enregistrements.

#### Bug Fix

Corriger le bug de copie de session en √©chec

### v1.4.1 - 2025.01.04

####Correction de probl√®mes

* Les outils de chat prennent en charge l'envoi uniquement d'images sans message.

R√©parer le probl√®me d'envoi d'images de l'interface OpenAI a √©chou√©.

* Correction des param√®tres Quality, Style, ApiVersion manquants dans les param√®tres de l'outil de chat OpanAI et Azure=

### v1.4.0 - 2024.12.30

####Nouveau fonctionnement

* (Fonctionnalit√© exp√©rimentale) Cllama (llama.cpp) prend en charge les mod√®les multimodaux, capables de traiter des images.

Tous les param√®tres de type "Blueprint" ont maintenant des descriptions d√©taill√©es.

### v1.3.4 - 2024.12.05

####Nouvelle fonctionnalit√©

* OpenAI prend en charge l'API de vision

####Correction de probl√®mes

R√©parer l'erreur lors du param√©trage de stream=false d'OpenAI.

### v1.3.3 - 2024.11.25

####Nouvelle fonctionnalit√©

* Supporte UE-5.5

####Correction de probl√®mes

* R√©paration de certains probl√®mes de non-application des plans.

### v1.3.2 - 2024.10.10

####R√©paration de probl√®mes

* Correction de l'effondrement de cllama lors de l'arr√™t manuel de la demande.

R√©soudre le probl√®me de l'absence des fichiers ggml.dll et llama.dll lors de la cr√©ation du package pour la version Windows du magasin en ligne.

V√©rifiez lors de la cr√©ation de la demande si vous √™tes dans le GameThread.

### v1.3.1 - 2024.9.30

####Nouvelle fonctionnalit√©

* Ajouter un SystemTemplateViewer, permettant de consulter et d'utiliser des centaines de mod√®les de param√®tres syst√®me.

####R√©paration du probl√®me

R√©parez le plugin t√©l√©charg√© depuis la boutique, llama.cpp ne trouve pas la biblioth√®que de liens

* Correction du probl√®me de chemin trop long de LLAMACpp

R√©parez l'erreur de lien llama.dll apr√®s avoir emball√© Windows.

* Corriger le probl√®me de lecture des chemins de fichiers sur ios/android

R√©parer l'erreur de nom de configuration de Cllame

### v1.3.0 - 2024.9.23

####Nouvelle fonctionnalit√© majeure

* Int√©gr√© avec llama.cpp, prend en charge l'ex√©cution hors ligne locale de grands mod√®les.

### v1.2.0 - 2024.08.20

####Nouvelle fonction

* Prise en charge de l'√©dition d'images OpenAI / Variation d'images

* Prise en charge de l'API Ollama, prise en charge de l'obtention automatique de la liste des mod√®les pris en charge par Ollama.

### v1.1.0 - 2024.08.07

####Nouveau fonctionnalit√©

Soutien au plan d'action

### v1.0.0 - 2024.08.05

####Nouveau fonction

* Fonctionnalit√©s de base compl√®tes

Soutenir OpenAI, Azure, Claude, Gemini.

* √âditeur de chat int√©gr√© avec des fonctionnalit√©s compl√®tes.

--8<-- "footer_fr.md"


> Ce message a √©t√© traduit en utilisant ChatGPT, veuillez donner votre [**feedback**](https://github.com/disenone/wiki_blog/issues/new)Identifier tout manquement. 
