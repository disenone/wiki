---
layout: post
title: UE Plugin AIChatPlus Dokumentation
tags:
- dev
- game
- UE
- UnreanEngine
- UE4
- UE5
- Editor
- Editor Plus
- Editor Plugin
- AI Chat
- Chatbot
- Image Generation
- OpenAI
- Azure
- Claude
- Gemini
- Ollama
description: UE Plugin AIChatPlus Anleitung
---

<meta property="og:title" content="UE Êèí‰ª∂ AIChatPlus ËØ¥ÊòéÊñáÊ°£" />

#UE Êèí‰ª∂ AIChatPlus User Manual

##√ñffentliches Lagerhaus

[UE.AIChatPlus.Public](https://github.com/disenone/UE.AIChatPlus.Public)

##Plugin erhalten.

[AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

##Plugin-Beschreibung

Dieses Plugin unterst√ºtzt UE5.2+.

UE.AIChatPlus ist ein UnrealEngine-Plugin, das die Kommunikation mit verschiedenen GPT AI-Chat-Diensten erm√∂glicht. Derzeit unterst√ºtzte Dienste sind OpenAI (ChatGPT, DALL-E), Azure OpenAI (ChatGPT, DALL-E), Claude, Google Gemini, Ollama und llama.cpp lokal im Offline-Modus. In Zukunft werden weiterhin weitere Dienstanbieter unterst√ºtzt. Die Implementierung basiert auf asynchronen REST-Anfragen, ist leistungsf√§hig und erleichtert es UE-Entwicklern, diese AI-Chat-Dienste zu integrieren.

Gleichzeitig enth√§lt UE.AIChatPlus ein Editor-Tool, mit dem man diese KI-Chat-Dienste direkt im Editor nutzen kann, um Texte und Bilder zu generieren, Bilder zu analysieren usw.

##Gebrauchsanweisung

###Editor-Chat-Tool

Men√ºleiste Werkzeuge -> AIChatPlus -> AIChat √∂ffnet das von dem Plugin bereitgestellte Editor-Chat-Tool.

![](assets/img/2024-ue-aichatplus/chat_tool3.png)


Das Tool unterst√ºtzt die Textgenerierung, Textchat, die Bilderzeugung und Bildanalyse.

Die Benutzeroberfl√§che des Werkzeugs sieht ungef√§hr so aus:

![text chat](assets/img/2024-ue-aichatplus/chat_tool2.png)

![image chat](assets/img/2024-ue-aichatplus/chat_tool.png)

####Hauptfunktionen

Offline Large Model: Integration of the llama.cpp library, supporting local offline execution of large models.

* Text-Chat: Klicken Sie auf die Schaltfl√§che `Neuen Chat` in der linken unteren Ecke, um eine neue Text-Chat-Sitzung zu erstellen.

* Bildgenerierung: Klicken Sie auf die Schaltfl√§che `Neues Bild-Chat` in der linken unteren Ecke, um eine neue Bildgenerierungssitzung zu erstellen.

Bildanalyse: Einige Chat-Dienste von 'New Chat' unterst√ºtzen das Senden von Bildern, wie zum Beispiel Claude, Google Gemini. Klicken Sie einfach auf die Schaltfl√§che üñºÔ∏è oder üé® oben im Eingabefeld, um das zu sendende Bild zu laden.

* Unterst√ºtzte Blaupausen (Blueprint): Unterst√ºtzung f√ºr die Erstellung von API-Anfragen f√ºr Textchats, Bildgenerierung und weitere Funktionen.

Festlegen des aktuellen Chat-Charakters: Das Dropdown-Men√º √ºber dem Chat-Fenster erm√∂glicht die Auswahl des aktuellen Charakters, von dem die Texte gesendet werden. Dies erm√∂glicht die Simulation verschiedener Charaktere zur Anpassung des KI-Chats.

Leeren der Konversation: Das X-Symbol oben im Chatfenster kann verwendet werden, um den Verlaufsnachrichten der aktuellen Konversation zu l√∂schen.

Gespr√§chsvorlage: Hunderte von integrierten Gespr√§chssettings stehen zur Verf√ºgung, um h√§ufig auftretende Probleme einfach zu behandeln.

Globale Einstellungen: Klicken Sie auf die Schaltfl√§che "Einstellungen" unten links, um das Fenster f√ºr die globalen Einstellungen zu √∂ffnen. Hier k√∂nnen Sie den Standard-Text-Chat, den API-Dienst f√ºr die Bildgenerierung und die spezifischen Parameter f√ºr jeden API-Dienst festlegen. Die Einstellungen werden automatisch im Projektverzeichnis `$(ProjectFolder)/Saved/AIChatPlusEditor` gespeichert.

* Gespr√§chseinstellungen: Klicken Sie auf die Schaltfl√§che "Einstellungen" oberhalb des Chatfensters, um das Einstellungsfenster des aktuellen Gespr√§chs zu √∂ffnen. Es wird unterst√ºtzt, den Gespr√§chsnamen zu √§ndern, den verwendeten API-Dienst anzupassen und spezifische Parameter f√ºr die API jeder Sitzung unabh√§ngig festzulegen. Die Gespr√§chst Einstellungen werden automatisch im `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions` gespeichert.

√Ñndern des Chat-Inhalts: Wenn Sie mit der Maus √ºber einen Chat-Inhalt fahren, wird eine Schaltfl√§che zur Inhaltssteuerung f√ºr diesen einzelnen Chat-Inhalt angezeigt. Zu den Optionen geh√∂ren das Neugenerieren des Inhalts, das Bearbeiten, Kopieren, L√∂schen sowie das erneute Generieren von Inhalten unten (f√ºr Inhalte, bei denen der Benutzer die Rolle des Absenders hat).

* Bildanzeige: Bei der Bilderzeugung √∂ffnet ein Klick auf das Bild das Bildansichtsfenster (ImageViewer), das das Speichern des Bildes als PNG/UE-Textur unterst√ºtzt. Die Textur kann direkt im Inhaltsbrowser (Content Browser) angezeigt werden, was die Verwendung von Bildern im Editor erleichtert. Au√üerdem werden Funktionen wie das L√∂schen von Bildern, das erneute Generieren von Bildern und das Fortsetzen der Generierung weiterer Bilder unterst√ºtzt. F√ºr den Editor unter Windows wird zus√§tzlich das Kopieren von Bildern unterst√ºtzt, sodass Bilder direkt in die Zwischenablage kopiert werden k√∂nnen, was die Benutzung erleichtert. Die Bilder, die w√§hrend der Sitzung generiert werden, werden automatisch in jedem Sitzungsordner gespeichert, normalerweise unter dem Pfad `$(ProjectFolder)/Saved/AIChatPlusEditor/Sessions/${GUID}/images`.

Bauplan:

![blueprint](assets/img/2024-ue-aichatplus/blueprint.png)

Allgemeine Einstellungen:

![global settings](assets/img/2024-ue-aichatplus/global_setting.png)

Konversationseinstellungen:

![session settings](assets/img/2024-ue-aichatplus/session_setting.png)

Bearbeiten Sie den Chat-Inhalt:

![chat edit](assets/img/2024-ue-aichatplus/chat_edit.png)

Bildbetrachter:

![image viewer](assets/img/2024-ue-aichatplus/image_viewer.png)

Verwendung von Offline-Gro√ümodellen

![offline model](assets/img/2024-ue-aichatplus/offline_model.png)

Dialogvorlage

![system template](assets/img/2024-ue-aichatplus/system_template.png)

###Kerncode Einf√ºhrung

Derzeit ist das Plugin in folgende Module unterteilt:

AIChatPlusCommon: Runtime-Modul, das f√ºr die Verarbeitung von verschiedenen AI-API-Anfragen und die Analyse von Antwortinhalten zust√§ndig ist.

AIChatPlusEditor: Editor-Modul, verantwortlich f√ºr die Implementierung des Editor-KI-Chat-Tools.

AIChatPlusCllama: Laufzeitmodul (Runtime), das die Schnittstelle und Parameter von llama.cpp kapselt und die Offline-Ausf√ºhrung gro√üer Modelle erm√∂glicht.

* Thirdparty/LLAMACpp: Laufzeit-Drittanbieter-Modul, das die dynamischen Bibliotheken und Header-Dateien von llama.cpp integriert.

Der UClass, der f√ºr das Senden von Anfragen zust√§ndig ist, ist FAIChatPlus_xxxChatRequest. Jeder API-Dienst hat sein eigenes unabh√§ngiges Request UClass. Die Antworten auf die Anfragen werden durch die UClass UAIChatPlus_ChatHandlerBase/UAIChatPlus_ImageHandlerBase erhalten, es ist nur erforderlich, die entsprechenden R√ºckruffunktionen zu registrieren.

Bevor eine Anfrage gesendet wird, m√ºssen die API-Parameter und die Nachricht festgelegt werden. Dies geschieht √ºber FAIChatPlus_xxxChatRequestBody. Der spezifische Inhalt der Antwort wird im FAIChatPlus_xxxChatResponseBody analysiert, und beim Empfang des R√ºckrufs kann das ResponseBody √ºber eine spezielle Schnittstelle abgerufen werden.

Weitere Quellcodedetails sind im UE Shop erh√§ltlich: [AIChatPlus](https://www.unrealengine.com/marketplace/zh-CN/product/aichatplus-ai-chat-integration-openai-azure-claude-gemini)

## Cllama(llama.cpp)

###Verwenden Sie das Offline-Modell Cllama (llama.cpp) mit dem Editor-Tool.

Dieser Text lautet auf Deutsch:

Hier sind Anweisungen zur Verwendung des Offline-Modells llama.cpp im AIChatPlus-Editor-Tool.

* Zuerst das Offline-Modell von der HuggingFace-Website herunterladen: [Qwen1.5-1.8B-Chat-Q8_0.gguf](https://huggingface.co/second-state/Qwen1.5-1.8B-Chat-GGUF/resolve/main/Qwen1.5-1.8B-Chat-Q8_0.gguf)

Legen Sie das Modell in einen bestimmten Ordner, zum Beispiel im Verzeichnis Content/LLAMA des Spielprojekts.

```shell
E:/UE/projects/FP_Test1/Content/LLAMA
> ls
qwen1.5-1_8b-chat-q8_0.gguf*
```

* √ñffnen Sie das AIChatPlus-Bearbeitungswerkzeug: Tools -> AIChatPlus -> AIChat, erstellen Sie eine neue Chatsitzung und √∂ffnen Sie die Konfigurationsseite der Sitzung.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_1.png)

Stellen Sie die API auf Cllama ein, aktivieren Sie die benutzerdefinierten API-Einstellungen, f√ºgen Sie den Modellsuchpfad hinzu und w√§hlen Sie ein Modell aus.

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_2.png)

* Lass uns chatten!!

![guide editor](assets/img/2024-ue-aichatplus/guide_editor_3.png)

###Der Editor verwendet das Offline-Modell Cllama (llama.cpp) zur Bearbeitung von Bildern.

Laden Sie das Offline-Modell MobileVLM_V2-1.7B-GGUF von der HuggingFace-Website herunter und legen Sie es ebenfalls im Verzeichnis Content/LLAMA ab: [ggml-model-q4_k.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/ggml-model-q4_k.gguf)Âíå [mmproj-model-f16.gguf](https://huggingface.co/ZiangWu/MobileVLM_V2-1.7B-GGUF/resolve/main/mmproj-model-f16.gguf)I am sorry, but there is nothing to translate in the text you provided.

* Modell f√ºr die Sitzung festlegen:

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_1.png)

* Bild senden, um den Chat zu starten

![guide editor](assets/img/2024-ue-aichatplus/guide_cllama_vision_2.png)

###Der Code verwendet das Offline-Modell Cllama (llama.cpp).

Die folgende Anleitung beschreibt, wie man das Offline-Modell llama.cpp im Code verwendet.

Zuerst m√ºssen die Modell-Dateien ebenfalls in den Ordner Content/LLAMA heruntergeladen werden.

√Ñndern Sie den Code, um einen Befehl hinzuzuf√ºgen und √ºber diesen Befehl eine Nachricht an das Offline-Modell zu senden.

```c++
#include "Common/AIChatPlus_Log.h"
#include "Common_Cllama/AIChatPlus_CllamaChatRequest.h"

void AddTestCommand()
{
	IConsoleManager::Get().RegisterConsoleCommand(
		TEXT("AIChatPlus.TestChat"),
		TEXT("Test Chat."),
		FConsoleCommandDelegate::CreateLambda([]()
		{
			if (!FModuleManager::GetModulePtr<FAIChatPlusCommon>(TEXT("AIChatPlusCommon"))) return;

			TWeakObjectPtr<UAIChatPlus_ChatHandlerBase> HandlerObject = UAIChatPlus_ChatHandlerBase::New();
			// Cllama
			FAIChatPlus_CllamaChatRequestOptions Options;
			Options.ModelPath.FilePath = FPaths::ProjectContentDir() / "LLAMA" / "qwen1.5-1_8b-chat-q8_0.gguf";
			Options.NumPredict = 400;
			Options.bStream = true;
			// Options.StopSequences.Emplace(TEXT("json"));
			auto RequestPtr = UAIChatPlus_CllamaChatRequest::CreateWithOptionsAndMessages(
				Options,
				{
					{"You are a chat bot", EAIChatPlus_ChatRole::System},
					{"who are you", EAIChatPlus_ChatRole::User}
				});

			HandlerObject->BindChatRequest(RequestPtr);
			const FName ApiName = TEnumTraits<EAIChatPlus_ChatApiProvider>::ToName(RequestPtr->GetApiProvider());

			HandlerObject->OnMessage.AddLambda([ApiName](const FString& Message)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] Message: [%s]"), *ApiName.ToString(), *Message);
			});
			HandlerObject->OnStarted.AddLambda([ApiName]()
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestStarted"), *ApiName.ToString());
			});
			HandlerObject->OnFailed.AddLambda([ApiName](const FAIChatPlus_ResponseErrorBase& InError)
			{
				UE_LOG(AIChatPlus_Internal, Error, TEXT("TestChat[%s] RequestFailed: %s "), *ApiName.ToString(), *InError.GetDescription());
			});
			HandlerObject->OnUpdated.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestUpdated"), *ApiName.ToString());
			});
			HandlerObject->OnFinished.AddLambda([ApiName](const FAIChatPlus_ResponseBodyBase& ResponseBody)
			{
				UE_LOG(AIChatPlus_Internal, Display, TEXT("TestChat[%s] RequestFinished"), *ApiName.ToString());
			});

			RequestPtr->SendRequest();
		}),
		ECVF_Default
	);
}
```

* Nach der erneuten Kompilierung k√∂nnen Sie im Editor Cmd den Befehl verwenden, um die Ausgaberesultate des gro√üen Modells im Protokoll OutputLog zu sehen.

![guide code](assets/img/2024-ue-aichatplus/guide_code_1.png)

###Blueprint verwendet das Offline-Modell llama.cpp

Die folgende Anleitung erl√§utert, wie man Offline-Modelle wie llama.cpp in Blueprints verwendet.

* Klicken Sie mit der rechten Maustaste im Blueprint und erstellen Sie einen Knoten `Send Cllama Chat Request`.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_1.png)

* Erstellen Sie den Options-Knoten und setzen Sie `Stream=true, ModelPath="E:\UE\projects\FP_Test1\Content\LLAMA\qwen1.5-1_8b-chat-q8_0.gguf"`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_2.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_3.png)

Erstellen Sie Nachrichten, f√ºgen Sie jeweils eine Systemnachricht und eine Benutzernachricht hinzu.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Erstellen Sie einen Delegaten, der die Ausgaben des Modells annimmt und auf dem Bildschirm ausgibt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

Eine vollst√§ndige Blaupause sieht so aus, f√ºhren Sie die Blaupause aus und Sie werden die Nachricht sehen, die auf dem Bildschirm erscheint, die das Drucken eines gro√üen Modells best√§tigt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_7.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_8.png)

## OpenAI

###Editor verwendet OpenAI-Chat

* √ñffnen Sie das Chat-Tool Tools -> AIChatPlus -> AIChat, erstellen Sie eine neue Chatsitzung New Chat, setzen Sie die Sitzung ChatApi auf OpenAI, setzen Sie die Schnittstellenparameter.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_1.png)

* Chat starten:

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_2.png)

Wechseln Sie das Modell auf gpt-4o / gpt-4o-mini, um die Bildanalysefunktionen von OpenAI zu nutzen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_chat_3.png)

###Der Editor verwendet OpenAI, um Bilder zu bearbeiten (erstellen/√§ndern/variieren).

* Erstellen Sie im Chat-Tool eine neue Bildunterhaltung New Image Chat, √§ndern Sie die Sitzungseinstellungen auf OpenAI und passen Sie die Parameter an.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_1.png)

Erstellen von Bildern

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_2.png)

* √Ñndern Sie das Bild, √§ndern Sie den Bild-Chattyp in Bearbeiten und laden Sie zwei Bilder hoch, eines ist das Originalbild und das andere ist die Maske, wobei die transparenten Bereiche (Alpha-Kanal = 0) die Stellen darstellen, die ge√§ndert werden m√ºssen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_4.png)

* √Ñndern Sie den Konversationstyp von Image Chat in Variation und laden Sie ein Bild hoch. OpenAI wird eine Variation des originalen Bildes zur√ºckgeben.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_tool_image_5.png)

###Blueprint nutzt OpenAI Model Chats.

In der Blaupause mit der rechten Maustaste einen Knoten `Send OpenAI Chat Request In World` erstellen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_1.png)

* Erstellen Sie einen Options-Knoten und setzen Sie `Stream=true, Api Key="Ihr API-Schl√ºssel von OpenAI"`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_2.png)

* Erstellen Sie Nachrichten und f√ºgen Sie jeweils eine Systemnachricht und eine Benutzernachricht hinzu.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_4.png)

Erstellen Sie einen Delegaten, der die Ausgabeinformationen des Modells empf√§ngt und auf dem Bildschirm ausgibt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_5.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_blueprint_6.png)

* Der vollst√§ndige Blueprint sieht so aus, wenn Sie den Blueprint ausf√ºhren, k√∂nnen Sie den Spielbildschirm sehen, der die Nachrichten des zur√ºckgegebenen gro√üen Modells anzeigt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_3.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_blueprint_4.png)

###Entwurf mit OpenAI erstelltes Bild.

In der Blaupause mit der rechten Maustaste einen Knoten namens "Send OpenAI Image Request" erstellen und "In Prompt="a beautiful butterfly"" einstellen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_1.png)

Erstellen Sie den Options-Knoten und legen Sie `Api Key="Ihr API-Schl√ºssel von OpenAI"` fest.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_2.png)

* Binde das On Images-Ereignis und speichere die Bilder auf der lokalen Festplatte.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_3.png)

* Der vollst√§ndige Plan sieht so aus, indem Sie den Plan ausf√ºhren, k√∂nnen Sie die Bilder am angegebenen Speicherort sehen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_openai_image_blueprint_5.png)

## Azure

###Der Editor verwendet Azure.

Erstellen einer neuen Unterhaltung (New Chat), indem Sie ChatApi auf Azure umstellen und die Api-Parameter von Azure einrichten.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_1.png)

Beginnen Sie zu plaudern.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_chat_2.png)

###Editor verwendet Azure, um Bilder zu erstellen.

Erstellen Sie ein neues Bild-Chat-Gespr√§ch (*New Image Chat*), √§ndern Sie *ChatApi* auf *Azure* und konfigurieren Sie die Azure-API-Parameter. Beachten Sie, dass bei Verwendung des *dall-e-2*-Modells die Parameter *Quality* und *Stype* auf *not_use* gesetzt werden m√ºssen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_1.png)

* Beginnen Sie den Chat und lassen Sie Azure Bilder erstellen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_tool_image_2.png)

###Blueprint verwenden Azure Chat.

Erstellen Sie das folgende Blueprint, richten Sie die Azure-Optionen ein, und klicken Sie auf Ausf√ºhren, um die von Azure zur√ºckgegebenen Chatnachrichten auf dem Bildschirm zu sehen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_chat_2.png)

###Blueprint verwendet Azure zur Erstellung von Bildern.

Erstelle das folgende Schema, konfiguriere die Azure-Optionen, klicke auf "Ausf√ºhren". Wenn das Erstellen des Bildes erfolgreich ist, wird die Meldung "Bild erstellen erfolgreich" auf dem Bildschirm angezeigt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_azure_blueprint_image_1.png)

Gem√§√ü den oben genannten Einstellungen wird das Bild im Pfad D:\Dwnloads\butterfly.png gespeichert.

## Claude

###Der Editor verwendet Claude f√ºr Chat und Bildanalyse.

* Neue Unterhaltung erstellen (New Chat), √§ndern Sie ChatApi in Claude und stellen Sie die Api-Parameter f√ºr Claude ein.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_1.png)

* Chat starten

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_tool_chat_2.png)

###Blueprint verwenden Claude zum Chatten und Analysieren von Bildern.

In der Blaupause mit der rechten Maustaste einen Knoten namens "Send Claude Chat Request" erstellen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_1.png)

* Erstellen Sie einen Options-Knoten und setzen Sie `Stream=true, Api Key="Ihr API-Schl√ºssel von Clude", Max Output Tokens=1024`

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_2.png)

Erstellen von Nachrichten, Erstellen eines Texture2D aus einer Datei und Erstellen von AIChatPlusTexture aus dem Texture2D, dann Hinzuf√ºgen des AIChatPlusTexture zur Nachricht.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_3.png)

* Erstelle ein Event wie im obigen Tutorial und drucke die Informationen auf den Spielbildschirm.

Die vollst√§ndige Blaupause sieht so aus, f√ºhre die Blaupause aus und du wirst auf dem Spielschirm die Nachricht sehen, die das gedruckte gro√üe Modell zur√ºckgibt.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_4.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_claude_blueprint_5.png)

## Ollama

###Ollama abrufen

* Die Installationspakete k√∂nnen √ºber die offizielle Ollama-Website heruntergeladen werden: [ollama.com](https://ollama.com/)

Sie k√∂nnen Ollama √ºber die von anderen bereitgestellte Ollama-Schnittstelle verwenden.

###Editor verwendet Ollama, um zu chatten und Bilder zu analysieren.

Erstellen Sie einen neuen Chat und √§ndern Sie ChatApi in Ollama. Legen Sie die Api-Parameter f√ºr Ollama fest. Wenn es sich um einen Text-Chat handelt, setzen Sie das Modell auf den Text-Modus, wie z.B. llama3.1; Wenn Bilder verarbeitet werden m√ºssen, w√§hlen Sie ein Modell aus, das die Bildverarbeitung unterst√ºtzt, z.B. moondream.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_1.png)

Beginnen Sie mit dem Chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_tool_chat_2.png)

###Blueprint verwenden Ollama zum Chatten und Analysieren von Bildern.

Erstellen Sie das folgende Schema, konfigurieren Sie die Ollama-Optionen, klicken Sie auf Ausf√ºhren und Sie werden die Chat-Nachrichten sehen, die von Ollama auf dem Bildschirm ausgegeben werden.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_ollama_blueprint_chat_2.png)

## Gemini

###Der Editor verwendet Gemini.

* Neue Sitzung (New Chat), √§ndern Sie ChatApi zu Gemini und setzen Sie die Api-Parameter von Gemini.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_1.png)

Bitte √ºbersetzen Sie den folgenden Text ins Deutsche: 

"Beginne den Chat."

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_chat_2.png)

###Der Editor verwendet Gemini, um Audio zu senden.

* W√§hlen Sie Audio aus Datei lesen / Audio aus Asset lesen / Audio vom Mikrofon aufnehmen, um die zu sendende Audio zu generieren.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_1.png)

Beginnen Sie mit dem Chatten.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_tool_sound_2.png)

###Verwenden Sie den Blueprint f√ºr Chats mit Gemini.

Erstellen Sie folgendes Blueprint, stellen Sie die Gemini Options ein, klicken Sie auf Ausf√ºhren, und Sie k√∂nnen die von Gemini zur√ºckgegebenen Chatnachrichten auf dem Bildschirm sehen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_chat_2.png)

###Blueprint verwendet Gemini zum Senden von Audio.

Erstellen Sie das folgende Blueprint, laden Sie die Audio-Datei, konfigurieren Sie die Gemini-Optionen und klicken Sie auf Ausf√ºhren. Dann k√∂nnen Sie die im Bildschirm ausgegebenen Chat-Nachrichten sehen, die von Gemini nach der Verarbeitung der Audiodatei zur√ºckgegeben werden.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_gemini_blueprint_sound_2.png)

## Deepseek

###Der Editor verwendet Deepseek.

Erstellen Sie einen neuen Chat, √§ndern Sie ChatApi in OpenAi und konfigurieren Sie die API-Parameter von Deepseek. F√ºgen Sie ein neues Kandidatenmodell namens Deepseek-Chat hinzu und setzen Sie das Modell auf Deepseek-Chat.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_1.png)

Beginnen Sie mit dem Gespr√§ch.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_tool_chat_2.png)

###Blaupause verwendet Deepseek-Chat

Erstellen Sie das folgende Blueprint und richten Sie die entsprechenden Request-Optionen f√ºr Deepseek ein, einschlie√ülich Model, Base Url, End Point Url, ApiKey und weiteren Parametern. Klicken Sie auf Ausf√ºhren, um die von Gemini zur√ºckgegebenen Chatinformationen auf dem Bildschirm anzuzeigen.

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_1.png)

![guide bludprint](assets/img/2024-ue-aichatplus/guide_deepseek_blueprint_chat_2.png)

##√Ñnderungsprotokoll

### v1.5.1 - 2025.01.30

####Neue Funktion

* Nur Gemini darf Audio abspielen.

* Optimierung der Methode zur Erfassung von PCMData, um die Audiodaten erst beim Erzeugen von B64 zu dekomprimieren.

Bitte f√ºge zwei Callbacks hinzu: OnMessageFinished und OnImagesFinished.

Optimieren Sie die Gemini-Methode, um automatisch die Methode basierend auf bStream zu erhalten.

F√ºgen Sie einige Blueprint-Funktionen hinzu, um das Umwandeln von Wrapper in tats√§chliche Typen zu erleichtern und Response-Nachrichten und Fehler abzurufen.

#### Bug Fix

Behebung des Problems mit mehrfachem Aufruf von "Request Finish".

### v1.5.0 - 2025.01.29

####Neue Funktion

* Unterst√ºtzung f√ºr die Audio√ºbertragung an Gemini

* Die Editor-Tools unterst√ºtzen das Senden von Audio und Aufnahmen.

#### Bug Fix

* Behebung des Bugs beim Kopieren von Sitzungen

### v1.4.1 - 2025.01.04

####Problembehebung

* Der Chat-Tool unterst√ºtzt das Senden von Bildern ohne Textnachrichten.

* Behebung des Problems mit dem Senden von Bildern √ºber die OpenAI-Schnittstelle fehlgeschlagen.

Beheben der fehlenden Parameter Quality, Style und ApiVersion in den Einstellungen von OpanAI und Azure-Chat-Tools.

### v1.4.0 - 2024.12.30

####Neue Funktionen

* (Experimentelle Funktion) Cllama (llama.cpp) unterst√ºtzt multimodale Modelle und kann Bilder verarbeiten.

Alle Blauprint-Typenparameter wurden mit detaillierten Hinweisen versehen.

### v1.3.4 - 2024.12.05

####Neue Funktionen

* OpenAI unterst√ºtzt die Vision-API

####Fehlerbehebung

* Behebung des Fehlers, wenn OpenAI stream=false ist.

### v1.3.3 - 2024.11.25

####Neue Funktionen

Unterst√ºtzt UE-5.5.

####Problembehebung

Fixing the issue of certain blueprints not working.

### v1.3.2 - 2024.10.10

####Fehlerbehebung

* Beheben Sie den Absturz von cllama beim manuellen Stoppen der Anfrage.

* Behebung des Problems, dass die ggml.dll und llama.dll Dateien in der heruntergeladenen Win-Version des Marktplatzes nicht gefunden werden k√∂nnen.

Beim Erstellen der Anfrage √ºberpr√ºfen, ob sich im GameThread befindet.

### v1.3.1 - 2024.9.30

####Neue Funktion

F√ºgen Sie einen SystemTemplateViewer hinzu, mit dem Sie Hunderte von Systemeinstellungs-Templates anzeigen und verwenden k√∂nnen.

####Fehlerbehebung

Repariere das Plugin, das aus dem App Store heruntergeladen wurde. Llama.cpp kann die Verkn√ºpfungsbibliothek nicht finden.

Behebung des Problems mit zu langen Pfaden in LLAMACpp.

Beheben Sie den Linkfehler llama.dll nach dem Windows-Paket.

Beheben Sie das Problem beim Lesen des Dateipfads in iOS/Android.

* Behebung des Namensfehlers in den Cllame-Einstellungen

### v1.3.0 - 2024.9.23

####Wichtige neue Funktionen

Integriert llama.cpp, unterst√ºtzt die Ausf√ºhrung gro√üer Modelle offline lokal.

### v1.2.0 - 2024.08.20

####Neue Funktion

* Unterst√ºtzung f√ºr OpenAI Bildbearbeitung/Bildvariation

Unterst√ºtzt Ollama API, um die Liste der von Ollama unterst√ºtzten Modelle automatisch abzurufen.

### v1.1.0 - 2024.08.07

####Neue Funktionen

Unterst√ºtzung der Blaupause

### v1.0.0 - 2024.08.05

####Neue Funktion

* Vollst√§ndige Grundfunktionen

* Unterst√ºtzung f√ºr OpenAI, Azure, Claude, Gemini

* Integrierter, funktionaler Editor-Chat-Tool

--8<-- "footer_de.md"


> Dieser Beitrag wurde mit ChatGPT √ºbersetzt, bitte hinterlassen Sie Ihr [**Feedback**](https://github.com/disenone/wiki_blog/issues/new)weist auf etwaige Auslassungen hin. 
